{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import gc\n",
    "\n",
    "from dataset import CoughDataset\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 data_path, \n",
    "                 batch_size=32, \n",
    "                 num_workers=4, \n",
    "                 train_size=0.8, \n",
    "                 val_size=0.1, \n",
    "                 test_size=0.1,\n",
    "                 duration=10.0,\n",
    "                 sample_rate=48000,\n",
    "                 channels=1,\n",
    "                 n_mels=64,\n",
    "                 n_fft=1024, \n",
    "                 top_db=80):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.duration = duration\n",
    "        self.sample_rate = sample_rate\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.top_db = top_db\n",
    "        \n",
    "        if self.train_size + self.val_size + self.test_size != 1.0:\n",
    "            raise Exception('train_size + val_size + test_size must be equal to 1.0')\n",
    "        \n",
    "        \n",
    "        self.dataset = CoughDataset(df=self.df, \n",
    "                               data_path=self.data_path,\n",
    "                               duration=self.duration,\n",
    "                               sample_rate=self.sample_rate,\n",
    "                               channels=self.channels,\n",
    "                               n_mels=self.n_mels,\n",
    "                               n_fft=self.n_fft,\n",
    "                               top_db=self.top_db)\n",
    "        self.classes = self.dataset.label_encoder.classes_\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(self.dataset, [self.train_size, self.val_size, self.test_size])\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughModel(nn.Module):\n",
    "    def __init__(self, n_class=3) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Fully-connected layers\n",
    "        self.fc1 = nn.Linear(in_features=128 * 3 * 104, out_features=512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=n_class)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten the tensor for the fully-connected layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully-connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCoughClassifier(pl.LightningModule):\n",
    "    def __init__(self, classes, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Classes   \n",
    "        self.classes = classes\n",
    "        num_classes = len(self.classes)\n",
    "        \n",
    "        # Model\n",
    "        self.model = CoughModel(num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Loss and metrics\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes)\n",
    "        self.confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes)\n",
    "        self.test_confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        y_pred = self.model(x)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = self.accuracy(y_pred, y)\n",
    "        self.log('train_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        f1_score = self.f1_score(y_pred, y)\n",
    "        self.log('train_f1_score', f1_score, on_step=True, on_epoch=True, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        y_pred = self.model(x)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = self.accuracy(y_pred, y)\n",
    "        self.log('val_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        f1_score = self.f1_score(y_pred, y)\n",
    "        self.log('val_f1_score', f1_score, on_step=True, on_epoch=True, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        y_pred = self.model(x)\n",
    "        \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        self.log('test_loss', loss)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = self.accuracy(y_pred, y)\n",
    "        self.log('test_accuracy', accuracy)\n",
    "        f1_score = self.f1_score(y_pred, y)\n",
    "        self.log('test_f1_score', f1_score)\n",
    "        \n",
    "        confusion_matrix = self.confusion_matrix(y_pred, y)\n",
    "        self.test_confusion_matrix += confusion_matrix\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        cm = self.test_confusion_matrix.numpy()\n",
    "        plot_confusion_matrix(cm, self.classes, filename='confusion_matrix.png')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILE = 'data/metadata_compiled.csv'\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "metadata_df = pd.read_csv(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_df = metadata_df[metadata_df['status'].isna() == False]\n",
    "filtered_df = not_nan_df[not_nan_df['cough_detected'] > 0.9]    # TODO: Set as a hyperparameter\n",
    "filtered_df[['uuid', 'cough_detected', 'SNR', 'age', 'gender', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = CoughDataModule(df=filtered_df, data_path=DATA_PATH, n_fft=1024, n_mels=64, sample_rate=16000,)\n",
    "classes = data_module.classes\n",
    "\n",
    "classifier = LitCoughClassifier(classes, learning_rate=1e-3)\n",
    "\n",
    "test_sample = data_module.test_dataset[0][0]\n",
    "print('Sample input size:', test_sample.shape)\n",
    "summary(classifier, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            torch.manual_seed(69)  # noice\n",
    "\n",
    "            wandb_logger = WandbLogger(log_model=True)\n",
    "\n",
    "            data_module = CoughDataModule(\n",
    "                df=filtered_df,\n",
    "                data_path=DATA_PATH,\n",
    "                batch_size=config.batch_size,\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_fft=config.n_fft,\n",
    "                n_mels=config.n_mels)\n",
    "            classes = data_module.classes\n",
    "\n",
    "            classifier = LitCoughClassifier(classes, learning_rate=config.learning_rate)\n",
    "\n",
    "            accelerator = None\n",
    "            if torch.cuda.is_available():\n",
    "                accelerator = 'gpu'\n",
    "            elif torch.backends.mps.is_available():\n",
    "                accelerator = 'cpu'  # MPS is not implemented in PyTorch yet\n",
    "\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.max_epochs,\n",
    "                logger=wandb_logger,\n",
    "                accelerator=accelerator\n",
    "            )\n",
    "\n",
    "            trainer.fit(classifier, data_module)\n",
    "            trainer.test(classifier, data_module)\n",
    "\n",
    "            wandb.finish()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            wandb.finish()\n",
    "            raise e\n",
    "\n",
    "        del wandb_logger\n",
    "        del data_module\n",
    "        del classifier\n",
    "        del trainer\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"method\": \"bayes\",\n",
    "  \"metric\": {\n",
    "        \"name\": \"val_accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "    \"batch_size\": {\n",
    "        \"values\": [32, 64, 128]\n",
    "    },\n",
    "    \"max_epochs\": {\n",
    "        \"values\": [1]\n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"min\": 0.001,\n",
    "        \"max\": 0.01\n",
    "    },\n",
    "    \"sample_rate\": {\n",
    "      \"values\": [16000]\n",
    "    },\n",
    "    \"n_fft\": {\n",
    "      \"values\": [1024]\n",
    "    },\n",
    "    \"n_mels\": {\n",
    "      \"values\": [64]\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='cough-classifier', entity='dl-miniproject')\n",
    "\n",
    "wandb.agent(sweep_id, function=train, count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
