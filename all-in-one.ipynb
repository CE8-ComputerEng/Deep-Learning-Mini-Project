{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import gc\n",
    "\n",
    "from dataset import CoughDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 data_path, \n",
    "                 batch_size=32, \n",
    "                 num_workers=4, \n",
    "                 train_size=0.8, \n",
    "                 val_size=0.1, \n",
    "                 test_size=0.1,\n",
    "                 duration=10.0,\n",
    "                 sample_rate=48000,\n",
    "                 channels=1,\n",
    "                 n_mels=64,\n",
    "                 n_fft=1024, \n",
    "                 top_db=80):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.duration = duration\n",
    "        self.sample_rate = sample_rate\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.top_db = top_db\n",
    "        \n",
    "        if self.train_size + self.val_size + self.test_size != 1.0:\n",
    "            raise Exception('train_size + val_size + test_size must be equal to 1.0')\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        dataset = CoughDataset(df=self.df, \n",
    "                               data_path=self.data_path,\n",
    "                               duration=self.duration,\n",
    "                               sample_rate=self.sample_rate,\n",
    "                               channels=self.channels,\n",
    "                               n_mels=self.n_mels,\n",
    "                               n_fft=self.n_fft,\n",
    "                               top_db=self.top_db)\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(dataset, [self.train_size, self.val_size, self.test_size])\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "\n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "\n",
    "        # Forth Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=3)\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCoughClassifier(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Model\n",
    "        self.model = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Metrics\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=3)\n",
    "        self.f1 = torchmetrics.F1Score(task='multiclass', num_classes=3)\n",
    "        # self.precision_recall_curve = torchmetrics.PrecisionRecallCurve(task='multiclass', num_classes=3)\n",
    "        # self.confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=3)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss, on_epoch=True, logger=True)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = self.accuracy(y_hat, y)\n",
    "        self.log('train_accuracy', accuracy, on_epoch=True, prog_bar=True, logger=True)\n",
    "        f1 = self.f1(y_hat, y)\n",
    "        self.log('train_f1', f1, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        \n",
    "        # TODO: Move to dataset\n",
    "        # # Normalize the input\n",
    "        # x = (x - x.mean()) / x.std()\n",
    "        \n",
    "        y_hat = self.model(x)\n",
    "        \n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, on_epoch=True, logger=True)\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = self.accuracy(y_hat, y)\n",
    "        self.log('val_accuracy', accuracy, on_epoch=True, logger=True)\n",
    "        f1 = self.f1(y_hat, y)\n",
    "        self.log('val_f1', f1, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILE = 'data/metadata_compiled.csv'\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "metadata_df = pd.read_csv(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_df = metadata_df[metadata_df['status'].isna() == False]\n",
    "filtered_df = not_nan_df[not_nan_df['cough_detected'] > 0.9]    # TODO: Set as a hyperparameter\n",
    "filtered_df[['uuid', 'cough_detected', 'SNR', 'age', 'gender', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        try:    \n",
    "            torch.manual_seed(69) # noice\n",
    "            \n",
    "            wandb_logger = WandbLogger(log_model=True)\n",
    "            \n",
    "            data_module = CoughDataModule(df=filtered_df, \n",
    "                              data_path=DATA_PATH, \n",
    "                              batch_size=config.batch_size, \n",
    "                              )\n",
    "\n",
    "            model = CoughModel()\n",
    "            classifier = LitCoughClassifier(model=model, \n",
    "                                            learning_rate=config.learning_rate)\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.max_epochs,\n",
    "                logger=wandb_logger,\n",
    "            )\n",
    "            \n",
    "            trainer.fit(classifier, data_module)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            wandb.finish()\n",
    "            raise e\n",
    "        \n",
    "        del wandb_logger\n",
    "        del data_module\n",
    "        del model\n",
    "        del classifier\n",
    "        del trainer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"method\": \"bayes\",\n",
    "  \"metric\": {\n",
    "        \"name\": \"1_val/sharpe\",\n",
    "        \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "    \"batch_size\": {\n",
    "        \"values\": [32, 64, 128]\n",
    "    },\n",
    "    \"max_epochs\": {\n",
    "        \"values\": [30, 45, 60]\n",
    "    },\n",
    "    \"learning_rate\": {\n",
    "        \"min\": 0.001,\n",
    "        \"max\": 0.01\n",
    "    },\n",
    "    \"sample_rate\": {\n",
    "      \"values\": [16000, 22050, 44100, 48000]\n",
    "    },\n",
    "    \"n_fft\": {\n",
    "      \"values\": [512, 1024, 2048]\n",
    "    },\n",
    "    \"n_mels\": {\n",
    "      \"values\": [32, 64, 128, 256]\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='cough-classifier', entity='dl-miniproject')\n",
    "\n",
    "wandb.agent(sweep_id, function=train, count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
