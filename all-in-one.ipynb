{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import gc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from dataset import CoughDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Transformer implementation. Make sure to run the cell. Also, we recommend you do this after getting your SelfAttention implementation working\n",
    "# WRITTEN BY Holger Severin Bovbjerg <hsbo@es.aau.dk>\n",
    "# Adapted by Sarthak Yadav <sarthaky@es.aau.dk> for this assignment\n",
    "# KWT model based on model from https://github.com/ID56/Torch-KWT/blob/main/models/kwt.py\"\"\"\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch\n",
    "import torch.fft\n",
    "from torch import nn, einsum\n",
    "\n",
    "# Basically vision transformer, ViT that accepts MFCC + SpecAug. Refer to:\n",
    "# https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Pre layer normalization\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, fn):\n",
    "        \"\"\"\n",
    "        Initialises PreNorm module\n",
    "        :param dim: model dimension\n",
    "        :param fn: torch module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward method for PreNorm module\n",
    "        :param x: input tensor\n",
    "        :param kwargs: Keyword arguments\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "class PostNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Post layer normalization\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, fn):\n",
    "        \"\"\"\n",
    "        Initialises PostNorm module\n",
    "        :param dim: model dimension\n",
    "        :param fn: torch module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward method for PostNorm module\n",
    "        :param x: input tensor\n",
    "        :param kwargs: Keyword arguments\n",
    "        :return: PostNorm output\n",
    "        \"\"\"\n",
    "        return self.norm(self.fn(x, **kwargs))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Feed forward model\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        \"\"\"\n",
    "        Initialises FeedForward module\n",
    "        :param dim: feedforward dim\n",
    "        :param hidden_dim: hidden dimension of feedforward layer\n",
    "        :param dropout: feedforward dropout percentage\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward method for feedforward module\n",
    "        :param x: input tensor\n",
    "        :return: FeedForward output\n",
    "        \"\"\"\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SHA(nn.Module):\n",
    "    def __init__(self, head_dim, attn_drop=0.):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        # print(f\"in SHA, q:{q.shape}, k:{k.shape}, v:{v.shape}\")\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = (attn @ v)\n",
    "        # print(\"output shape:\", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MHA(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim_head\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            SHA(self.head_dim) for _ in range(self.num_heads)\n",
    "        ])\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "                nn.Linear(inner_dim, dim),\n",
    "                nn.Dropout(dropout)\n",
    "            ) if project_out else nn.Identity() \n",
    "  \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward method for Attention module\n",
    "        :param x: input tensor\n",
    "        :return: Attention module output\n",
    "        \"\"\"\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "\n",
    "        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 3, 0, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        o = []\n",
    "        for i in range(self.num_heads):\n",
    "            head_i = self.attention_heads[i](q[i],k[i],v[i]).unsqueeze(0)\n",
    "            o.append(head_i)\n",
    "        o = torch.concat(o, dim=0)\n",
    "        o = o.permute(1, 2, 0, 3).reshape(B, N, -1)\n",
    "\n",
    "        return self.to_out(o)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer model\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, pre_norm=True, dropout=0., mha_block=MHA):\n",
    "        \"\"\"\n",
    "        Initialises Transformer model\n",
    "        :param dim: transformer dimension\n",
    "        :param depth: number of transformer layers\n",
    "        :param heads: number of attention heads for each transformer layer\n",
    "        :param dim_head: dimension of each attention head\n",
    "        :param mlp_dim: MLP dimension\n",
    "        :param pre_norm: specifies whether PreNorm (True) or PostNorm (False) is used\n",
    "        :param dropout: dropout percentage of Attention of FeedForward modules\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        P_Norm = PreNorm if pre_norm else PostNorm\n",
    "        if mha_block is None:\n",
    "          mha_block = MHA\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                P_Norm(dim, mha_block(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
    "                P_Norm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward method for Transformer model\n",
    "        :param x: input tensor\n",
    "        :return: Tuple of model output, hidden states of transformer and attentions from each transformer layer\n",
    "        \"\"\"\n",
    "        hidden_states = []\n",
    "        attentions = []\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            attentions.append(x)\n",
    "            x = ff(x) + x\n",
    "            hidden_states.append(x)\n",
    "        return x, hidden_states, attentions\n",
    "\n",
    "\n",
    "class KWT(nn.Module):\n",
    "    \"\"\"\n",
    "    KWT model\n",
    "    \"\"\"\n",
    "    def __init__(self, input_res, patch_res, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=1,\n",
    "                 dim_head=64, dropout=0., emb_dropout=0., pre_norm=True, mha_block=MHA, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialises KWT model\n",
    "        :param input_res: input spectrogram size\n",
    "        :param patch_res: patch size\n",
    "        :param num_classes: number of keyword classes\n",
    "        :param dim: transformer dimension\n",
    "        :param depth: number of transformer layers\n",
    "        :param heads: number of attention heads\n",
    "        :param mlp_dim: MLP dimension\n",
    "        :param pool: specifies whether CLS token or average pooling of transformer model is used for classification\n",
    "        :param channels: Number of input channels\n",
    "        :param dim_head: dimension of attention heads\n",
    "        :param dropout: dropout of transformer attention and feed forward layers\n",
    "        :param emb_dropout: dropout of embeddings\n",
    "        :param pre_norm: specifies whether PreNorm (True) or PostNorm (False) is used\n",
    "        :param kwargs: Keyword arguments\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        num_patches = int(input_res[0] / patch_res[0] * input_res[1] / patch_res[1])\n",
    "\n",
    "        patch_dim = channels * patch_res[0] * patch_res[1]\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_res[0], p2=patch_res[1]),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        self.mask_embedding = nn.Parameter(torch.FloatTensor(dim).uniform_())\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, pre_norm, dropout, mha_block=mha_block)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        # Create classification head\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None, output_hidden_states=False, output_attentions=False):\n",
    "        \"\"\"\n",
    "        Forward method of KWT model\n",
    "        :param x: input tensor\n",
    "        :param mask: input mask\n",
    "        :param output_hidden_states: specifies whether hidden states are output\n",
    "        :param output_attentions: specifies whether attentions are output\n",
    "        :return: KWT model output, if output_hidden_states and/or output_attentions the classification head is skipped\n",
    "        \"\"\"\n",
    "        x = self.to_patch_embedding(x)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        # Add cls token embedding\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # Mask input\n",
    "        if mask is not None:\n",
    "            x[mask] = self.mask_embedding\n",
    "\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x, hidden_states, attentions = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "\n",
    "        if any([output_hidden_states, output_attentions]):\n",
    "            outputs = (self.mlp_head(x), hidden_states) if output_hidden_states else (self.mlp_head(x), )\n",
    "            outputs = outputs + (attentions, ) if output_attentions else outputs\n",
    "            return outputs\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 data_path, \n",
    "                 batch_size=32, \n",
    "                 num_workers=4, \n",
    "                 train_size=0.8, \n",
    "                 val_size=0.1, \n",
    "                 test_size=0.1,\n",
    "                 duration=10.0,\n",
    "                 sample_rate=48000,\n",
    "                 channels=1,\n",
    "                 n_mels=64,\n",
    "                 n_fft=1024, \n",
    "                 top_db=80,\n",
    "                 augment=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.duration = duration\n",
    "        self.sample_rate = sample_rate\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.top_db = top_db\n",
    "        self.augment = augment\n",
    "        if self.train_size + self.val_size + self.test_size != 1.0:\n",
    "            raise Exception('train_size + val_size + test_size must be equal to 1.0')\n",
    "    \n",
    "        self.dataset = CoughDataset(df=self.df, \n",
    "                            data_path=self.data_path,\n",
    "                            duration=self.duration,\n",
    "                            sample_rate=self.sample_rate,\n",
    "                            channels=self.channels,\n",
    "                            n_mels=self.n_mels,\n",
    "                            n_fft=self.n_fft,\n",
    "                            top_db=self.top_db,\n",
    "                            augment=self.augment)\n",
    "\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(self.dataset, [self.train_size, self.val_size, self.test_size])\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FILE = 'data/metadata_compiled.csv'\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "\n",
    "metadata_df = pd.read_csv(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14733/422034823.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  filtered_df = filtered_df[filtered_df['status'] == 'healthy'].sample(frac=0.3, random_state=42).append(filtered_df[filtered_df['status'] != 'healthy'])\n"
     ]
    }
   ],
   "source": [
    "not_nan_df = metadata_df[metadata_df['status'].isna() == False]\n",
    "filtered_df = not_nan_df[not_nan_df['cough_detected'] > 0.6]    # TODO: Set as a hyperparameter\n",
    "filtered_df[['uuid', 'cough_detected', 'SNR', 'age', 'gender', 'status']]\n",
    "# Augment the Covid-19 samples\n",
    "\n",
    "# remove 50% of the healthy samples\n",
    "filtered_df = filtered_df[filtered_df['status'] == 'healthy'].sample(frac=0.3, random_state=42).append(filtered_df[filtered_df['status'] != 'healthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title self-attention\n",
    "from torch.nn.modules.module import T\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, head_dim):\n",
    "    super().__init__()\n",
    "    self.head_dim = head_dim\n",
    "    ## Complete what the scale should be. Then uncomment\n",
    "    self.scale = self.head_dim ** -0.5\n",
    "\n",
    "  def forward(self, q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    q, k, v are query, key and value tensors, respectively of shapes (B, N, C)\n",
    "    where B is Batch Size\n",
    "          N is number of patches\n",
    "          C is the dimensions\n",
    "\n",
    "    You have to \n",
    "\n",
    "    1. compute the dot product between q and k\n",
    "    2. scale it\n",
    "    3. apply softmax to get weights\n",
    "    4. project v with weights\n",
    "    \"\"\"\n",
    "    \"\"\"qk_dot = torch.matmul(q[0,:,:],k[0,:,:].T)\n",
    "    wv = qk_dot * self.scale\n",
    "    n = torch.nn.Softmax(dim=1)\n",
    "    wv_softmax = n(wv)\n",
    "    wv_softmax_weighted = torch.matmul(wv_softmax, v)\"\"\"\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title MultiHeadAttention, already implemented\n",
    "class MultiHeadAttentionCustom(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim_head\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.attention_heads = nn.ModuleList([\n",
    "            SelfAttention(self.head_dim) for _ in range(self.num_heads)\n",
    "        ])\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "                nn.Linear(inner_dim, dim),\n",
    "                nn.Dropout(dropout)\n",
    "            ) if project_out else nn.Identity() \n",
    "  \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward method for Attention module\n",
    "        :param x: input tensor\n",
    "        :return: Attention module output\n",
    "        \"\"\"\n",
    "\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        #print(\"in attention qkv shape:\", qkv.shape)\n",
    "        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 3, 0, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        o = []\n",
    "        for i in range(self.num_heads):\n",
    "            head_i = self.attention_heads[i](q[i],k[i],v[i]).unsqueeze(0)\n",
    "            o.append(head_i)\n",
    "        o = torch.concat(o, dim=0)\n",
    "        o = o.permute(1, 2, 0, 3).reshape(B, N, -1)\n",
    "\n",
    "        return self.to_out(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(trained_model, set):\n",
    "    predictor = trained_model.model.eval().to(torch.device('cuda'))\n",
    "    test_set = set\n",
    "\n",
    "    labels, predictions = [], []\n",
    "    for i in range(len(test_set)):\n",
    "        img, label = test_set[i]\n",
    "        labels.append(label)\n",
    "        with torch.no_grad():\n",
    "            img = img.to(torch.device('cuda'))\n",
    "            pred = predictor(torch.unsqueeze(img, 0))[0].cpu().numpy()\n",
    "            predictions.append(np.argmax(pred))\n",
    "        \n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(labels, predictions, labels=[0,1,2])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['COVID-19', 'healthy', 'symptomatic'])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title This is the PyTorch-Lightning Module implementation, which takes care of a lot of boilerplate code related to training for us.\n",
    "class KWTLightning(pl.LightningModule):\n",
    "  def __init__(self, hparams, mha_block):\n",
    "    super().__init__()\n",
    "    self.w1 = hparams[\"w1\"]\n",
    "    self.w2 = hparams[\"w2\"]\n",
    "    self.w3 = hparams[\"w3\"]\n",
    "    self.model = KWT(**hparams, mha_block=mha_block)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "  \n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "    x, y = train_batch\n",
    "    # make a weight tensor with size of 3\n",
    "    w = torch.ones(3)\n",
    "    # set the weight of the 0 class to 2\n",
    "    w[0] = self.w1 # Covid\n",
    "    w[1] = self.w2 # Healthy\n",
    "    w[2] = self.w3 #\n",
    "    w = w.to(device='cuda:0')\n",
    "    preds = self.model(x)\n",
    "    loss = nn.functional.cross_entropy(preds, y, w)\n",
    "    acc = (preds > 0.5).float().mean()\n",
    "    self.log(\"train_loss\", loss)\n",
    "    self.log(\"train_accuracy\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "    return loss\n",
    "  \n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "    x, y = val_batch\n",
    "    preds = self.model(x)\n",
    "    loss = nn.functional.cross_entropy(preds, y)\n",
    "    acc = (preds.argmax(dim=-1) == y).float().mean()\n",
    "    self.log('val_loss', loss)\n",
    "    self.log(\"val_accuracy\", acc, prog_bar=True, on_epoch=True)\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    preds = self.model(x)\n",
    "    loss = nn.functional.cross_entropy(preds, y)\n",
    "    acc = (preds.argmax(dim=-1) == y).float().mean()\n",
    "    self.log('test_loss', loss)\n",
    "    self.log(\"test_accuracy\", acc)\n",
    "    \n",
    "    \n",
    "def create_pl(mha_block, MODEL_HPARAMS):\n",
    "  kwt_pl = KWTLightning(MODEL_HPARAMS, mha_block)\n",
    "  return kwt_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        try:    \n",
    "            torch.manual_seed(69) # noice\n",
    "            \n",
    "            wandb_logger = WandbLogger(log_model=True)\n",
    "            \n",
    "            print(\"Loading data...\")\n",
    "            # Load first data patch, with no augmentation\n",
    "            data_module = CoughDataModule(df=filtered_df, \n",
    "                              data_path=DATA_PATH,\n",
    "                              duration=10.0,\n",
    "                              sample_rate=config.sample_rate,\n",
    "                              channels=1,\n",
    "                              n_mels=config.n_mels,\n",
    "                              n_fft=config.n_fft,\n",
    "                              top_db=80,\n",
    "                              )\n",
    "            # Load second data patch, with augmentation\n",
    "            data_module_aug = CoughDataModule(df=filtered_df, \n",
    "                              data_path=DATA_PATH,\n",
    "                              duration=10.0,\n",
    "                              sample_rate=config.sample_rate,\n",
    "                              channels=1,\n",
    "                              n_mels=config.n_mels,\n",
    "                              n_fft=config.n_fft,\n",
    "                              top_db=80,\n",
    "                              augment=True,\n",
    "                              )\n",
    "            # Get size of random sample of data\n",
    "            size = data_module.train_dataset[0][0].shape\n",
    "        \n",
    "            BATCH_SIZE = 128\n",
    "            N_CLASSES = 3\n",
    "            heads = 8\n",
    "            dim = 512\n",
    "            MODEL_HPARAMS = {\n",
    "                \"input_res\":[size[1], size[2]],\n",
    "                \"patch_res\":[size[1], 1],\n",
    "                \"num_classes\":N_CLASSES,\n",
    "                \"mlp_dim\":256,\n",
    "                \"dim\":dim,\n",
    "                \"heads\":heads,\n",
    "                \"dim_head\":dim//heads,       # dim_head should be dim divided by number of heads\n",
    "                \"depth\":6,\n",
    "                \"dropout\": 0.1,\n",
    "                \"emb_dropout\": 0.1\n",
    "            }\n",
    "            print(\"Size of random sample of data:\", size)\n",
    "            kwt_pl = create_pl(mha_block=MultiHeadAttentionCustom, MODEL_HPARAMS=MODEL_HPARAMS)\n",
    "            cuda_available = torch.cuda.is_available()\n",
    "            # Combine the two datamodules into one\n",
    "            print(\"Combining datasets...\")\n",
    "            train_set = torch.utils.data.ConcatDataset([data_module.train_dataset, data_module_aug.train_dataset])\n",
    "            val_set = torch.utils.data.ConcatDataset([data_module.val_dataset, data_module_aug.val_dataset])\n",
    "            test_set = torch.utils.data.ConcatDataset([data_module.test_dataset, data_module_aug.test_dataset])\n",
    "            print(data_module.dataset.label_encoder.classes_)\n",
    "            # Print how many Covid, Normal, and Pneumonia samples are in each set\n",
    "            #print(\"Test set class counts:\", count_labels(data_module.test_dataset))\n",
    "            #print(\"Train set class counts:\", count_labels(data_module.train_dataset))\n",
    "            #print(\"Val set class counts:\", count_labels(data_module.val_dataset))\n",
    "            print(data_module.dataset.class_counts)\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.max_epochs,\n",
    "                logger=wandb_logger,\n",
    "                accelerator='gpu' if cuda_available else None,\n",
    "            )\n",
    "            trainer.fit(kwt_pl, datamodule=data_module)\n",
    "            #trainer.fit(kwt_pl, data_module)\n",
    "            trainer.test(kwt_pl, test_set)\n",
    "            # plot confusion matrix from trainer\n",
    "            plot_confusion_matrix(kwt_pl, data_module.test_dataset)\n",
    "            #plot_confusion_matrix(kwt_pl, data_module.val_dataset)\n",
    "            #plot_confusion_matrix(kwt_pl, data_module.train_dataset)\n",
    "            \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            wandb.finish()\n",
    "            raise e\n",
    "        \n",
    "        del wandb_logger\n",
    "        del data_module\n",
    "        del model\n",
    "        del classifier\n",
    "        del trainer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        # set api key\n",
    "        api_keys = [\"72b34cc4c01608a271beb1a67ff4ce2ed54642b5\",\n",
    "                    \"2b1482b5655f56c6d538026fc7aa21fbc5d48ae2\",\n",
    "                    \"b37bf4266eea06e99d3d420a06937fa903d20e81\",\n",
    "                    \"db8b5ecab7932ebabc0b4abb2805c3cd32ab76d1\"]\n",
    "        \n",
    "        # choose random api key\n",
    "        key = random.choice(api_keys)\n",
    "        os.environ['WANDB_API_KEY'] = key\n",
    "        config = wandb.config\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        try:    \n",
    "            torch.manual_seed(69) # noice\n",
    "            \n",
    "            wandb_logger = WandbLogger(log_model=True)\n",
    "            \n",
    "            print(\"Loading data...\")\n",
    "            # Load first data patch, with no augmentation\n",
    "            data_module = CoughDataModule(df=filtered_df, \n",
    "                              data_path=DATA_PATH,\n",
    "                              duration=10.0,\n",
    "                              sample_rate=config.sample_rate,\n",
    "                              channels=1,\n",
    "                              n_mels=config.n_mels,\n",
    "                              n_fft=config.n_fft,\n",
    "                              top_db=80,\n",
    "                              )\n",
    "            # Load second data patch, with augmentation\n",
    "            size = data_module.train_dataset[0][0].shape\n",
    "            \n",
    "            N_CLASSES = 3\n",
    "            heads = config.heads\n",
    "            dim = config.dim\n",
    "            MODEL_HPARAMS = {\n",
    "                \"input_res\":[size[1], size[2]],\n",
    "                \"patch_res\":[size[1], 1],\n",
    "                \"num_classes\":N_CLASSES,\n",
    "                \"mlp_dim\":256,\n",
    "                \"dim\":dim,\n",
    "                \"heads\":heads,\n",
    "                \"dim_head\":dim//heads,       # dim_head should be dim divided by number of heads\n",
    "                \"depth\":6,\n",
    "                \"dropout\": 0.1,\n",
    "                \"emb_dropout\": 0.1,\n",
    "                \"w1\": config.w1,\n",
    "                \"w2\": config.w2,\n",
    "                \"w3\": config.w3,\n",
    "            }\n",
    "            print(\"Size of random sample of data:\", size)\n",
    "            kwt_pl = create_pl(mha_block=MultiHeadAttentionCustom, MODEL_HPARAMS=MODEL_HPARAMS)\n",
    "            cuda_available = torch.cuda.is_available()\n",
    "            # Combine the two datamodules into one\n",
    "            print(data_module.dataset.label_encoder.classes_)\n",
    "            print(data_module.dataset.class_counts)\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config.max_epochs,\n",
    "                logger=wandb_logger,\n",
    "                accelerator='gpu' if cuda_available else None,\n",
    "            )\n",
    "            trainer.fit(kwt_pl, data_module)\n",
    "            trainer.test(kwt_pl, data_module)\n",
    "            #plot_confusion_matrix(kwt_pl, data_module.test_dataset)\n",
    "            wandb.finish()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            wandb.finish()\n",
    "            raise e\n",
    "        \n",
    "        del wandb_logger\n",
    "        del data_module\n",
    "        del kwt_pl\n",
    "        del trainer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_module = CoughDataModule(df=filtered_df, \\n                    data_path=DATA_PATH,\\n                    duration=10.0,\\n                    sample_rate=16000,\\n                    channels=1,\\n                    n_mels=32,\\n                    n_fft=512,\\n                    top_db=80,\\n                    )\\n\\nsize = data_module.train_dataset[0][0].shape\\n        \\nBATCH_SIZE = 128\\nN_CLASSES = 3\\nheads = 8\\ndim = 512\\nMODEL_HPARAMS = {\\n    \"input_res\":[size[1], size[2]],\\n    \"patch_res\":[size[1], 1],\\n    \"num_classes\":N_CLASSES,\\n    \"mlp_dim\":256,\\n    \"dim\":dim,\\n    \"heads\":heads,\\n    \"dim_head\":dim//heads,       # dim_head should be dim divided by number of heads\\n    \"depth\":6,\\n    \"dropout\": 0.1,\\n    \"emb_dropout\": 0.1,\\n    \"w1\": 1.82125348139952,\\n    \"w2\": 0.6004520643168938,\\n    \"w3\": 1.0055852982334923,\\n}\\nkwt_pl = create_pl(mha_block=MultiHeadAttentionCustom, MODEL_HPARAMS=MODEL_HPARAMS)\\ntrainer = pl.Trainer(\\n    max_epochs=20,\\n    accelerator=\\'gpu\\',\\n)\\ntrainer.fit(kwt_pl, datamodule=data_module)\\n\\nplot_confusion_matrix(kwt_pl, data_module.test_dataset)\\n#plot_confusion_matrix(kwt_pl, data_module.train_dataset)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ata_module = CoughDataModule(df=filtered_df, \n",
    "                    data_path=DATA_PATH,\n",
    "                    duration=10.0,\n",
    "                    sample_rate=16000,\n",
    "                    channels=1,\n",
    "                    n_mels=64,\n",
    "                    n_fft=1024,\n",
    "                    top_db=80,\n",
    "                    )\n",
    "\n",
    "size = data_module.train_dataset[0][0].shape\n",
    "        \n",
    "BATCH_SIZE = 128\n",
    "N_CLASSES = 3\n",
    "heads = 16\n",
    "dim = 128\n",
    "MODEL_HPARAMS = {\n",
    "    \"input_res\":[size[1], size[2]],\n",
    "    \"patch_res\":[size[1], 1],\n",
    "    \"num_classes\":N_CLASSES,\n",
    "    \"mlp_dim\":256,\n",
    "    \"dim\":dim,\n",
    "    \"heads\":heads,\n",
    "    \"dim_head\":dim//heads,       # dim_head should be dim divided by number of heads\n",
    "    \"depth\":6,\n",
    "    \"dropout\": 0.1,\n",
    "    \"emb_dropout\": 0.1,\n",
    "    \"w1\": 1.19070340331838,\n",
    "    \"w2\": 0.6683332489272846,\n",
    "    \"w3\": 1.2838483214224414,\n",
    "}\n",
    "kwt_pl = create_pl(mha_block=MultiHeadAttentionCustom, MODEL_HPARAMS=MODEL_HPARAMS)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator='gpu',\n",
    ")\n",
    "trainer.fit(kwt_pl, datamodule=data_module)\n",
    "\n",
    "plot_confusion_matrix(kwt_pl, data_module.test_dataset)\n",
    "#plot_confusion_matrix(kwt_pl, data_module.train_dataset)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2d63ds5a\n",
      "Sweep URL: https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8jvfafm8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7691345658203603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.16752306541963086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5182773304219914\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkajmoerk\u001b[0m (\u001b[33mdl-miniproject\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_003035-8jvfafm8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/8jvfafm8' target=\"_blank\">ancient-sweep-1</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/8jvfafm8' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/8jvfafm8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 32, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 8.1 M \n",
      "-------------------------------\n",
      "8.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.1 M     Total params\n",
      "32.262    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:39<00:00,  1.40it/s, v_num=afm8, val_accuracy=0.364, train_accuracy=0.536]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:39<00:00,  1.40it/s, v_num=afm8, val_accuracy=0.364, train_accuracy=0.536]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.37857142090797424\n",
      "        test_loss           1.4781285524368286\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▇▇█▅▁</td></tr><tr><td>train_loss</td><td>▃▆▂█▁▇▅▄▃▂▅▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▂▅▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.37857</td></tr><tr><td>test_loss</td><td>1.47813</td></tr><tr><td>train_accuracy</td><td>0.53638</td></tr><tr><td>train_loss</td><td>0.88445</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36429</td></tr><tr><td>val_loss</td><td>1.47853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-1</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/8jvfafm8' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/8jvfafm8</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_003035-8jvfafm8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4p5b7kd4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.934905418646991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5873774373667774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.402770860983264\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukaskristensen\u001b[0m (\u001b[33mdl-miniproject\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_003929-4p5b7kd4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/4p5b7kd4' target=\"_blank\">clean-sweep-2</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/4p5b7kd4' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/4p5b7kd4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:38<00:00,  1.43it/s, v_num=7kd4, val_accuracy=0.507, train_accuracy=0.0472]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:38<00:00,  1.43it/s, v_num=7kd4, val_accuracy=0.507, train_accuracy=0.0472]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5178571343421936\n",
      "        test_loss           1.0023236274719238\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▄▃</td></tr><tr><td>train_loss</td><td>▁▄▄▃▆▄▅▅█▄▃▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.51786</td></tr><tr><td>test_loss</td><td>1.00232</td></tr><tr><td>train_accuracy</td><td>0.04717</td></tr><tr><td>train_loss</td><td>1.0842</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50714</td></tr><tr><td>val_loss</td><td>1.02269</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-sweep-2</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/4p5b7kd4' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/4p5b7kd4</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_003929-4p5b7kd4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9agr20fe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8468602148082427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.09021825708402915\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.208725721653738\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_004817-9agr20fe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9agr20fe' target=\"_blank\">soft-sweep-3</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9agr20fe' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9agr20fe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 32, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.843     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:39<00:00,  1.41it/s, v_num=20fe, val_accuracy=0.364, train_accuracy=0.641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:39<00:00,  1.41it/s, v_num=20fe, val_accuracy=0.364, train_accuracy=0.641]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.37857142090797424\n",
      "        test_loss           1.7148674726486206\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁█▇█▆</td></tr><tr><td>train_loss</td><td>▄▃▃▃▁▄▄▃█▂▃▂▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>██▁██</td></tr><tr><td>val_loss</td><td>█▁▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.37857</td></tr><tr><td>test_loss</td><td>1.71487</td></tr><tr><td>train_accuracy</td><td>0.64077</td></tr><tr><td>train_loss</td><td>0.99126</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36429</td></tr><tr><td>val_loss</td><td>1.69793</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-3</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9agr20fe' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9agr20fe</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_004817-9agr20fe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: syp30oh8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.983501772779714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.39841158726699344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.9570095180693232\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_005709-syp30oh8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/syp30oh8' target=\"_blank\">electric-sweep-4</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/syp30oh8' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/syp30oh8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:38<00:00,  1.42it/s, v_num=0oh8, val_accuracy=0.429, train_accuracy=0.00685] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:38<00:00,  1.42it/s, v_num=0oh8, val_accuracy=0.429, train_accuracy=0.00685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.86it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.42321428656578064\n",
      "        test_loss           1.0664384365081787\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▄▇▆</td></tr><tr><td>train_loss</td><td>▁▆▅▅▆▄▅▅█▃▂▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.42321</td></tr><tr><td>test_loss</td><td>1.06644</td></tr><tr><td>train_accuracy</td><td>0.00685</td></tr><tr><td>train_loss</td><td>1.06404</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.42857</td></tr><tr><td>val_loss</td><td>1.07416</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-4</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/syp30oh8' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/syp30oh8</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_005709-syp30oh8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 77iva7jl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6817437513242997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6904777997034405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.277674457549617\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_010601-77iva7jl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/77iva7jl' target=\"_blank\">lunar-sweep-5</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/77iva7jl' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/77iva7jl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:39<00:00,  1.40it/s, v_num=a7jl, val_accuracy=0.411, train_accuracy=0.679]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:40<00:00,  1.40it/s, v_num=a7jl, val_accuracy=0.411, train_accuracy=0.679]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.3946428596973419\n",
      "        test_loss           1.0321084260940552\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▇▇█</td></tr><tr><td>train_loss</td><td>▅▄▁▄▄▄▆▅▄█▆▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁█▃</td></tr><tr><td>val_loss</td><td>▇▅█▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.39464</td></tr><tr><td>test_loss</td><td>1.03211</td></tr><tr><td>train_accuracy</td><td>0.67887</td></tr><tr><td>train_loss</td><td>0.98913</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.41071</td></tr><tr><td>val_loss</td><td>1.06322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-5</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/77iva7jl' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/77iva7jl</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_010601-77iva7jl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qj8dojde with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8578253042333104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6982672488725363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.8276833098947455\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtudor_ph\u001b[0m (\u001b[33mdl-miniproject\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_011451-qj8dojde</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/qj8dojde' target=\"_blank\">deep-sweep-6</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/qj8dojde' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/qj8dojde</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=ojde, val_accuracy=0.405, train_accuracy=0.360]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=ojde, val_accuracy=0.405, train_accuracy=0.360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.46964284777641296\n",
      "        test_loss            1.047096848487854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▆█</td></tr><tr><td>train_loss</td><td>▅▅▁▅▄▅▆▄▄█▆▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▆▆█▆▁</td></tr><tr><td>val_loss</td><td>▃▁▁▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.46964</td></tr><tr><td>test_loss</td><td>1.0471</td></tr><tr><td>train_accuracy</td><td>0.36049</td></tr><tr><td>train_loss</td><td>1.04087</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.40536</td></tr><tr><td>val_loss</td><td>1.06627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-6</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/qj8dojde' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/qj8dojde</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_011451-qj8dojde/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lidipbke with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7149573057013257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.436084256972125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5057266686586916\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_012335-lidipbke</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/lidipbke' target=\"_blank\">serene-sweep-7</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/lidipbke' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/lidipbke</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=pbke, val_accuracy=0.420, train_accuracy=0.142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=pbke, val_accuracy=0.420, train_accuracy=0.142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.43214285373687744\n",
      "        test_loss            1.030235767364502\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▅▁▁▁</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▆▆█</td></tr><tr><td>val_loss</td><td>█▄▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.43214</td></tr><tr><td>test_loss</td><td>1.03024</td></tr><tr><td>train_accuracy</td><td>0.14167</td></tr><tr><td>train_loss</td><td>1.03804</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.41964</td></tr><tr><td>val_loss</td><td>1.05033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-sweep-7</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/lidipbke' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/lidipbke</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_012335-lidipbke/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vw96y3ra with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7171753943168864\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.3050339001586716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.089034472932724\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_013222-vw96y3ra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vw96y3ra' target=\"_blank\">prime-sweep-8</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vw96y3ra' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/vw96y3ra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=y3ra, val_accuracy=0.371, train_accuracy=0.0598]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=y3ra, val_accuracy=0.371, train_accuracy=0.0598]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.3642857074737549\n",
      "        test_loss           1.0954973697662354\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▄▁</td></tr><tr><td>train_loss</td><td>▁▅▄▅▅▄▅▅█▃▃▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.36429</td></tr><tr><td>test_loss</td><td>1.0955</td></tr><tr><td>train_accuracy</td><td>0.05982</td></tr><tr><td>train_loss</td><td>1.02218</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.37143</td></tr><tr><td>val_loss</td><td>1.10584</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-8</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vw96y3ra' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/vw96y3ra</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_013222-vw96y3ra/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tx4jew4s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8943004437327668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.58734549045506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.7014864041733104\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_014101-tx4jew4s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/tx4jew4s' target=\"_blank\">lemon-sweep-9</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/tx4jew4s' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/tx4jew4s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=ew4s, val_accuracy=0.452, train_accuracy=0.156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=ew4s, val_accuracy=0.452, train_accuracy=0.156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4803571403026581\n",
      "        test_loss           1.0100356340408325\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▆▂▂▁</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.48036</td></tr><tr><td>test_loss</td><td>1.01004</td></tr><tr><td>train_accuracy</td><td>0.15595</td></tr><tr><td>train_loss</td><td>1.05728</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.45179</td></tr><tr><td>val_loss</td><td>1.03161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-9</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/tx4jew4s' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/tx4jew4s</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_014101-tx4jew4s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: twsyx8iq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.9939002401307029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6946852838058628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.7076372538125506\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maxel-toft\u001b[0m (\u001b[33mdl-miniproject\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_014944-twsyx8iq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/twsyx8iq' target=\"_blank\">avid-sweep-10</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/twsyx8iq' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/twsyx8iq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=x8iq, val_accuracy=0.366, train_accuracy=0.759]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=x8iq, val_accuracy=0.366, train_accuracy=0.759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.3678571283817291\n",
      "        test_loss            1.072258710861206\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>train_loss</td><td>▅▄▁▄▄▄▆▆▄█▆▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁█▁</td></tr><tr><td>val_loss</td><td>█▅█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.36786</td></tr><tr><td>test_loss</td><td>1.07226</td></tr><tr><td>train_accuracy</td><td>0.75871</td></tr><tr><td>train_loss</td><td>0.97061</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36607</td></tr><tr><td>val_loss</td><td>1.0938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-10</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/twsyx8iq' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/twsyx8iq</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_014944-twsyx8iq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: epaisg3n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.922100265898848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.40834167228426055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.287599201014531\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_015826-epaisg3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/epaisg3n' target=\"_blank\">vibrant-sweep-11</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/epaisg3n' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/epaisg3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=sg3n, val_accuracy=0.361, train_accuracy=0.722]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=sg3n, val_accuracy=0.361, train_accuracy=0.722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.36071428656578064\n",
      "        test_loss           1.1681472063064575\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>▅▅▁▄▄▄▆▆▃█▆▃▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▂▂▂█▁</td></tr><tr><td>val_loss</td><td>▇▇▆▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.36071</td></tr><tr><td>test_loss</td><td>1.16815</td></tr><tr><td>train_accuracy</td><td>0.72217</td></tr><tr><td>train_loss</td><td>0.94763</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36071</td></tr><tr><td>val_loss</td><td>1.18294</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-sweep-11</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/epaisg3n' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/epaisg3n</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_015826-epaisg3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2rui8if7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7024740646349392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6800155802968513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.6691197765136765\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_020709-2rui8if7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2rui8if7' target=\"_blank\">brisk-sweep-12</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2rui8if7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2rui8if7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=8if7, val_accuracy=0.516, train_accuracy=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=8if7, val_accuracy=0.516, train_accuracy=0.155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.94it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5392857193946838\n",
      "        test_loss           0.9772041440010071\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▄▁▃▃</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▄▄▄█</td></tr><tr><td>val_loss</td><td>█▄▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.53929</td></tr><tr><td>test_loss</td><td>0.9772</td></tr><tr><td>train_accuracy</td><td>0.15536</td></tr><tr><td>train_loss</td><td>1.07326</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51607</td></tr><tr><td>val_loss</td><td>1.00512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-12</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2rui8if7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2rui8if7</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_020709-2rui8if7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9y18n6je with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8540570749180945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5675826062989469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.0694394706502446\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_021546-9y18n6je</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9y18n6je' target=\"_blank\">happy-sweep-13</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9y18n6je' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9y18n6je</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=n6je, val_accuracy=0.496, train_accuracy=0.00685] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=n6je, val_accuracy=0.496, train_accuracy=0.00685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5357142686843872\n",
      "        test_loss           1.0088258981704712\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▃▅▄</td></tr><tr><td>train_loss</td><td>▁▆▄▄▆▅▅▅█▄▃▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▆▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.53571</td></tr><tr><td>test_loss</td><td>1.00883</td></tr><tr><td>train_accuracy</td><td>0.00685</td></tr><tr><td>train_loss</td><td>1.10186</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.49643</td></tr><tr><td>val_loss</td><td>1.02717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-13</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9y18n6je' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9y18n6je</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_021546-9y18n6je/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sc6xuobo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.975190404622503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5319195617738103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.1395762321167933\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_022434-sc6xuobo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/sc6xuobo' target=\"_blank\">cerulean-sweep-14</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/sc6xuobo' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/sc6xuobo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=uobo, val_accuracy=0.479, train_accuracy=0.016]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=uobo, val_accuracy=0.479, train_accuracy=0.016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5142857432365417\n",
      "        test_loss            1.027366042137146\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▃▄▅</td></tr><tr><td>train_loss</td><td>▁▆▄▄▆▅▅▅█▄▃▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▅▆█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.51429</td></tr><tr><td>test_loss</td><td>1.02737</td></tr><tr><td>train_accuracy</td><td>0.016</td></tr><tr><td>train_loss</td><td>1.08037</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.47857</td></tr><tr><td>val_loss</td><td>1.03961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-14</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/sc6xuobo' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/sc6xuobo</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_022434-sc6xuobo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u7izg4y5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.9230935158434843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6317691777046318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2866744896194766\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_023312-u7izg4y5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/u7izg4y5' target=\"_blank\">astral-sweep-15</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/u7izg4y5' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/u7izg4y5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=g4y5, val_accuracy=0.509, train_accuracy=0.0477]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=g4y5, val_accuracy=0.509, train_accuracy=0.0477]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5482142567634583\n",
      "        test_loss           0.9957436919212341\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▃▇▆</td></tr><tr><td>train_loss</td><td>▁▅▄▄▅▄▅▅█▄▃▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.54821</td></tr><tr><td>test_loss</td><td>0.99574</td></tr><tr><td>train_accuracy</td><td>0.04769</td></tr><tr><td>train_loss</td><td>1.10237</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50893</td></tr><tr><td>val_loss</td><td>1.01669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-15</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/u7izg4y5' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/u7izg4y5</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_023312-u7izg4y5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hf46vukp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.4683308609797687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5792903405647567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.3547342272050602\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_024149-hf46vukp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hf46vukp' target=\"_blank\">expert-sweep-16</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hf46vukp' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hf46vukp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:34<00:00,  1.48it/s, v_num=vukp, val_accuracy=0.498, train_accuracy=0.133]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:34<00:00,  1.48it/s, v_num=vukp, val_accuracy=0.498, train_accuracy=0.133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5321428775787354\n",
      "        test_loss           0.9809048175811768\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▄▁▂▂</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.53214</td></tr><tr><td>test_loss</td><td>0.9809</td></tr><tr><td>train_accuracy</td><td>0.13296</td></tr><tr><td>train_loss</td><td>1.08214</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.49821</td></tr><tr><td>val_loss</td><td>1.00699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-16</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hf46vukp' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hf46vukp</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_024149-hf46vukp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bnpps8sn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6521551027457262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5267035669382606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.0973305918006615\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_025022-bnpps8sn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bnpps8sn' target=\"_blank\">fearless-sweep-17</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bnpps8sn' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bnpps8sn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=s8sn, val_accuracy=0.357, train_accuracy=0.703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=s8sn, val_accuracy=0.357, train_accuracy=0.703]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.36964285373687744\n",
      "        test_loss           1.0818854570388794\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>▅▅▁▄▄▄▆▅▄█▆▄▅▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▇▆▅▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.36964</td></tr><tr><td>test_loss</td><td>1.08189</td></tr><tr><td>train_accuracy</td><td>0.70275</td></tr><tr><td>train_loss</td><td>1.0157</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.35714</td></tr><tr><td>val_loss</td><td>1.10029</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-sweep-17</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bnpps8sn' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bnpps8sn</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_025022-bnpps8sn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ay7016u6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.2871978646699418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5812899754135719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.632901858296662\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_025859-ay7016u6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ay7016u6' target=\"_blank\">earnest-sweep-18</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ay7016u6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/ay7016u6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 2.5 M \n",
      "-------------------------------\n",
      "2.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 M     Total params\n",
      "9.875     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=16u6, val_accuracy=0.366, train_accuracy=0.598]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=16u6, val_accuracy=0.366, train_accuracy=0.598]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.38035714626312256\n",
      "        test_loss           1.0563266277313232\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>train_loss</td><td>▄▂▁▄▃▃▆▆▄█▆▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▆▄█▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.38036</td></tr><tr><td>test_loss</td><td>1.05633</td></tr><tr><td>train_accuracy</td><td>0.59769</td></tr><tr><td>train_loss</td><td>0.92991</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36607</td></tr><tr><td>val_loss</td><td>1.0892</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-18</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ay7016u6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/ay7016u6</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_025859-ay7016u6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wwmhwzln with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.791410014690733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.47111513032992747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.3866479970601788\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_030736-wwmhwzln</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wwmhwzln' target=\"_blank\">zany-sweep-19</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wwmhwzln' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/wwmhwzln</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=wzln, val_accuracy=0.457, train_accuracy=0.0852]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=wzln, val_accuracy=0.457, train_accuracy=0.0852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.46964284777641296\n",
      "        test_loss           1.0145270824432373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▂▁▃▂</td></tr><tr><td>train_loss</td><td>▁▄▄▄▅▄▅▅█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.46964</td></tr><tr><td>test_loss</td><td>1.01453</td></tr><tr><td>train_accuracy</td><td>0.08519</td></tr><tr><td>train_loss</td><td>1.0643</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.45714</td></tr><tr><td>val_loss</td><td>1.03363</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-19</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wwmhwzln' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/wwmhwzln</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_030736-wwmhwzln/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hs0lconb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.840311040786028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6062952569545108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.922297372570908\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_031616-hs0lconb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hs0lconb' target=\"_blank\">vibrant-sweep-20</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hs0lconb' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hs0lconb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=conb, val_accuracy=0.504, train_accuracy=0.00134] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=conb, val_accuracy=0.504, train_accuracy=0.00134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5196428298950195\n",
      "        test_loss            1.008307933807373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▂▂</td></tr><tr><td>train_loss</td><td>▁▇▅▅▆▅▅▆█▅▃▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▇███</td></tr><tr><td>val_loss</td><td>█▃▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.51964</td></tr><tr><td>test_loss</td><td>1.00831</td></tr><tr><td>train_accuracy</td><td>0.00134</td></tr><tr><td>train_loss</td><td>1.10697</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50357</td></tr><tr><td>val_loss</td><td>1.02709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-sweep-20</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hs0lconb' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hs0lconb</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_031616-hs0lconb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gvi0aymm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.565798391442965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5884846448820786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.6098189372569002\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_032459-gvi0aymm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/gvi0aymm' target=\"_blank\">splendid-sweep-21</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/gvi0aymm' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/gvi0aymm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=aymm, val_accuracy=0.488, train_accuracy=0.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=aymm, val_accuracy=0.488, train_accuracy=0.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.512499988079071\n",
      "        test_loss           1.0484485626220703\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▆▇▆▆▅▇█▆▃▅▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5125</td></tr><tr><td>test_loss</td><td>1.04845</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.10866</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.06755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-21</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/gvi0aymm' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/gvi0aymm</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_032459-gvi0aymm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rxotr7i1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7423398970538562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6076893200106877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.7988296648329958\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_033337-rxotr7i1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/rxotr7i1' target=\"_blank\">rose-sweep-22</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/rxotr7i1' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/rxotr7i1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=r7i1, val_accuracy=0.463, train_accuracy=0.234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=r7i1, val_accuracy=0.463, train_accuracy=0.234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4910714328289032\n",
      "        test_loss           0.9896599054336548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁█▆▃▂</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▅▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.49107</td></tr><tr><td>test_loss</td><td>0.98966</td></tr><tr><td>train_accuracy</td><td>0.23445</td></tr><tr><td>train_loss</td><td>1.06227</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4625</td></tr><tr><td>val_loss</td><td>1.0174</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-22</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/rxotr7i1' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/rxotr7i1</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_033337-rxotr7i1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wsv6y9gg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.820184856542568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6069894661397602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.4721733237036214\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_034219-wsv6y9gg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wsv6y9gg' target=\"_blank\">pious-sweep-23</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wsv6y9gg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/wsv6y9gg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 626])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 882 K \n",
      "-------------------------------\n",
      "882 K     Trainable params\n",
      "0         Non-trainable params\n",
      "882 K     Total params\n",
      "3.528     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=y9gg, val_accuracy=0.368, train_accuracy=0.226]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=y9gg, val_accuracy=0.368, train_accuracy=0.226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.3839285671710968\n",
      "        test_loss           1.0807514190673828\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁█▇▅▅</td></tr><tr><td>train_loss</td><td>▅▅▃▁▁█▇▄▄▄▅▄▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▁██▂</td></tr><tr><td>val_loss</td><td>▃█▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.38393</td></tr><tr><td>test_loss</td><td>1.08075</td></tr><tr><td>train_accuracy</td><td>0.22567</td></tr><tr><td>train_loss</td><td>0.98461</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.36786</td></tr><tr><td>val_loss</td><td>1.10705</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-23</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/wsv6y9gg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/wsv6y9gg</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_034219-wsv6y9gg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ym294y0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7315899420801792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6158685658494483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.5039068935295608\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_035057-2ym294y0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2ym294y0' target=\"_blank\">honest-sweep-24</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2ym294y0' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2ym294y0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=94y0, val_accuracy=0.482, train_accuracy=0.000372]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=94y0, val_accuracy=0.482, train_accuracy=0.000372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 0.5\n",
      "        test_loss           1.0926975011825562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▆▆▅▆▃▆▆▆▁▅▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▂▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5</td></tr><tr><td>test_loss</td><td>1.0927</td></tr><tr><td>train_accuracy</td><td>0.00037</td></tr><tr><td>train_loss</td><td>1.0998</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48214</td></tr><tr><td>val_loss</td><td>1.10788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-24</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2ym294y0' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2ym294y0</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_035057-2ym294y0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b1a5depc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.9542886468395344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6112491140103288\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.7788571500317671\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_035935-b1a5depc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/b1a5depc' target=\"_blank\">floral-sweep-25</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/b1a5depc' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/b1a5depc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=depc, val_accuracy=0.479, train_accuracy=0.000]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=depc, val_accuracy=0.479, train_accuracy=0.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.49642857909202576\n",
      "        test_loss           1.0426886081695557\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▅▇▆▅▅▆▇▅▂▄▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁█▇█▇</td></tr><tr><td>val_loss</td><td>█▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.49643</td></tr><tr><td>test_loss</td><td>1.04269</td></tr><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.1078</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.47857</td></tr><tr><td>val_loss</td><td>1.05852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-sweep-25</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/b1a5depc' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/b1a5depc</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_035935-b1a5depc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9uw33oh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8811896961680503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6990738740080161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.5147142514793587\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_040812-m9uw33oh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m9uw33oh' target=\"_blank\">peachy-sweep-26</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m9uw33oh' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m9uw33oh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=33oh, val_accuracy=0.482, train_accuracy=0.00112] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=33oh, val_accuracy=0.482, train_accuracy=0.00112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5053571462631226\n",
      "        test_loss           1.1084816455841064\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▂</td></tr><tr><td>train_loss</td><td>▁█▅▆▅▆▃▆▅▆▁▅▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▂▃▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50536</td></tr><tr><td>test_loss</td><td>1.10848</td></tr><tr><td>train_accuracy</td><td>0.00112</td></tr><tr><td>train_loss</td><td>1.10385</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48214</td></tr><tr><td>val_loss</td><td>1.12175</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-sweep-26</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m9uw33oh' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m9uw33oh</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_040812-m9uw33oh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j11czpbr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6836736224182485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6949006017243491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5669652339066542\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_041655-j11czpbr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/j11czpbr' target=\"_blank\">fine-sweep-27</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/j11czpbr' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/j11czpbr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=zpbr, val_accuracy=0.514, train_accuracy=0.177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=zpbr, val_accuracy=0.514, train_accuracy=0.177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5464285612106323\n",
      "        test_loss           0.9701803922653198\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▆▆▁▄█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▄▄▆█</td></tr><tr><td>val_loss</td><td>█▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.54643</td></tr><tr><td>test_loss</td><td>0.97018</td></tr><tr><td>train_accuracy</td><td>0.17679</td></tr><tr><td>train_loss</td><td>1.08299</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51429</td></tr><tr><td>val_loss</td><td>1.00025</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-27</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/j11czpbr' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/j11czpbr</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_041655-j11czpbr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9sgle3u0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.4260593559715322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6070739006168937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5150833017143492\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_042543-9sgle3u0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9sgle3u0' target=\"_blank\">lyric-sweep-28</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9sgle3u0' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9sgle3u0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=e3u0, val_accuracy=0.504, train_accuracy=0.186]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=e3u0, val_accuracy=0.504, train_accuracy=0.186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.512499988079071\n",
      "        test_loss           0.9686756730079651\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▃▁▁▄█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▄▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▃▃▃█</td></tr><tr><td>val_loss</td><td>█▅▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5125</td></tr><tr><td>test_loss</td><td>0.96868</td></tr><tr><td>train_accuracy</td><td>0.18557</td></tr><tr><td>train_loss</td><td>1.07173</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50357</td></tr><tr><td>val_loss</td><td>1.00053</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-28</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/9sgle3u0' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/9sgle3u0</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_042543-9sgle3u0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jq08l2xx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.997338623302553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6671860287555372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.3531383328448396\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_043427-jq08l2xx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/jq08l2xx' target=\"_blank\">fancy-sweep-29</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/jq08l2xx' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/jq08l2xx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=l2xx, val_accuracy=0.496, train_accuracy=0.0625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=l2xx, val_accuracy=0.496, train_accuracy=0.0625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5303571224212646\n",
      "        test_loss           1.0037568807601929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▅▅</td></tr><tr><td>train_loss</td><td>▁▅▄▄▆▅▅▅█▄▄▄▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.53036</td></tr><tr><td>test_loss</td><td>1.00376</td></tr><tr><td>train_accuracy</td><td>0.0625</td></tr><tr><td>train_loss</td><td>1.08236</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.49643</td></tr><tr><td>val_loss</td><td>1.02533</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-29</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/jq08l2xx' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/jq08l2xx</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_043427-jq08l2xx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eles2ag7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7423232014339127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6386740957566579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.8660152712302769\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_044302-eles2ag7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/eles2ag7' target=\"_blank\">soft-sweep-30</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/eles2ag7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/eles2ag7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=2ag7, val_accuracy=0.488, train_accuracy=0.00119] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=2ag7, val_accuracy=0.488, train_accuracy=0.00119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.512499988079071\n",
      "        test_loss           1.0096476078033447\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▂▂</td></tr><tr><td>train_loss</td><td>▁▇▅▅▆▆▅▆█▅▄▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5125</td></tr><tr><td>test_loss</td><td>1.00965</td></tr><tr><td>train_accuracy</td><td>0.00119</td></tr><tr><td>train_loss</td><td>1.11233</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.02762</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-30</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/eles2ag7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/eles2ag7</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_044302-eles2ag7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zw4hkspr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.568016586302584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6821197891303761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.516154131311541\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_045145-zw4hkspr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zw4hkspr' target=\"_blank\">laced-sweep-31</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zw4hkspr' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/zw4hkspr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 32, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 837 K \n",
      "-------------------------------\n",
      "837 K     Trainable params\n",
      "0         Non-trainable params\n",
      "837 K     Total params\n",
      "3.352     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.43it/s, v_num=kspr, val_accuracy=0.345, train_accuracy=0.00223] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.43it/s, v_num=kspr, val_accuracy=0.345, train_accuracy=0.00223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.3553571403026581\n",
      "        test_loss           1.0985153913497925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▃</td></tr><tr><td>train_loss</td><td>▄▄▃▄█▂▄▂▁▆▂▄▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>██▇▂▁</td></tr><tr><td>val_loss</td><td>▁▂▃█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.35536</td></tr><tr><td>test_loss</td><td>1.09852</td></tr><tr><td>train_accuracy</td><td>0.00223</td></tr><tr><td>train_loss</td><td>1.10086</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.34464</td></tr><tr><td>val_loss</td><td>1.10233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-31</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zw4hkspr' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/zw4hkspr</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_045145-zw4hkspr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yi6r07uq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.174096609259594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6990107521955745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.613080306996855\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_050028-yi6r07uq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/yi6r07uq' target=\"_blank\">neat-sweep-32</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/yi6r07uq' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/yi6r07uq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.44it/s, v_num=07uq, val_accuracy=0.511, train_accuracy=0.409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.44it/s, v_num=07uq, val_accuracy=0.511, train_accuracy=0.409]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.90it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5232142806053162\n",
      "        test_loss           0.9507424235343933\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▇█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▄▄█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▄▁▂▃█</td></tr><tr><td>val_loss</td><td>██▆▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.52321</td></tr><tr><td>test_loss</td><td>0.95074</td></tr><tr><td>train_accuracy</td><td>0.40908</td></tr><tr><td>train_loss</td><td>1.04734</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51071</td></tr><tr><td>val_loss</td><td>0.99181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-32</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/yi6r07uq' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/yi6r07uq</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_050028-yi6r07uq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: splbbvfp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.370755484135164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.689662965114389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.8628296922764425\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_050926-splbbvfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/splbbvfp' target=\"_blank\">cerulean-sweep-33</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/splbbvfp' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/splbbvfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=bvfp, val_accuracy=0.495, train_accuracy=0.0567]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=bvfp, val_accuracy=0.495, train_accuracy=0.0567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5232142806053162\n",
      "        test_loss           0.9848284125328064\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▂▅█</td></tr><tr><td>train_loss</td><td>▁▇▅▄▆▆▅▆█▆▅▅▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▇▇█▇</td></tr><tr><td>val_loss</td><td>█▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.52321</td></tr><tr><td>test_loss</td><td>0.98483</td></tr><tr><td>train_accuracy</td><td>0.0567</td></tr><tr><td>train_loss</td><td>1.10981</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.49464</td></tr><tr><td>val_loss</td><td>1.01154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-sweep-33</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/splbbvfp' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/splbbvfp</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_050926-splbbvfp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1c247vhj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.885120898165233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6594165946286352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2356696754362622\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_051814-1c247vhj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/1c247vhj' target=\"_blank\">dainty-sweep-34</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/1c247vhj' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/1c247vhj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=7vhj, val_accuracy=0.514, train_accuracy=0.059] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=7vhj, val_accuracy=0.514, train_accuracy=0.059]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5571428537368774\n",
      "        test_loss           0.9875346422195435\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▄▃</td></tr><tr><td>train_loss</td><td>▁▅▄▄▆▅▅▅█▅▄▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55714</td></tr><tr><td>test_loss</td><td>0.98753</td></tr><tr><td>train_accuracy</td><td>0.059</td></tr><tr><td>train_loss</td><td>1.10987</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51429</td></tr><tr><td>val_loss</td><td>1.01166</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-sweep-34</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/1c247vhj' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/1c247vhj</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_051814-1c247vhj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: knr2jsa1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.2196529546288088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.683800819982556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2518103151213835\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_052652-knr2jsa1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/knr2jsa1' target=\"_blank\">good-sweep-35</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/knr2jsa1' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/knr2jsa1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=jsa1, val_accuracy=0.518, train_accuracy=0.342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=jsa1, val_accuracy=0.518, train_accuracy=0.342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.550000011920929\n",
      "        test_loss           0.9552739858627319\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▆▃▆█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▅▄▅█▄▅▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▆▁▅▆█</td></tr><tr><td>val_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55</td></tr><tr><td>test_loss</td><td>0.95527</td></tr><tr><td>train_accuracy</td><td>0.34189</td></tr><tr><td>train_loss</td><td>1.08731</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51786</td></tr><tr><td>val_loss</td><td>0.99232</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-sweep-35</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/knr2jsa1' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/knr2jsa1</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_052652-knr2jsa1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cllpw9hu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.1709227809236349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.4881858257319535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5224796464690482\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_053530-cllpw9hu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/cllpw9hu' target=\"_blank\">electric-sweep-36</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/cllpw9hu' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/cllpw9hu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=w9hu, val_accuracy=0.445, train_accuracy=0.315]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=w9hu, val_accuracy=0.445, train_accuracy=0.315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4749999940395355\n",
      "        test_loss           0.9841274619102478\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▅█</td></tr><tr><td>train_loss</td><td>▁▃▃▃▅▄▄▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▃▃▃█</td></tr><tr><td>val_loss</td><td>█▇▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.475</td></tr><tr><td>test_loss</td><td>0.98413</td></tr><tr><td>train_accuracy</td><td>0.31451</td></tr><tr><td>train_loss</td><td>1.03528</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.44464</td></tr><tr><td>val_loss</td><td>1.01768</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-36</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/cllpw9hu' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/cllpw9hu</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_053530-cllpw9hu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v7f4alul with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.472145537443074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6308439923718184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.7815548864220785\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_054410-v7f4alul</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v7f4alul' target=\"_blank\">fast-sweep-37</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v7f4alul' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/v7f4alul</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=alul, val_accuracy=0.488, train_accuracy=0.321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=alul, val_accuracy=0.488, train_accuracy=0.321]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4910714328289032\n",
      "        test_loss            0.973755955696106\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▇▅█</td></tr><tr><td>train_loss</td><td>▁▃▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▃▃▃█</td></tr><tr><td>val_loss</td><td>█▆▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.49107</td></tr><tr><td>test_loss</td><td>0.97376</td></tr><tr><td>train_accuracy</td><td>0.32091</td></tr><tr><td>train_loss</td><td>1.05256</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.00542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-37</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v7f4alul' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/v7f4alul</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_054410-v7f4alul/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d1hnh3rv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.54231592888335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5539421021405587\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.4538807165584875\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_055247-d1hnh3rv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/d1hnh3rv' target=\"_blank\">sparkling-sweep-38</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/d1hnh3rv' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/d1hnh3rv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=h3rv, val_accuracy=0.484, train_accuracy=0.158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=h3rv, val_accuracy=0.484, train_accuracy=0.158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5053571462631226\n",
      "        test_loss           0.9883375763893127\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▄▁▃▁</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▄▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50536</td></tr><tr><td>test_loss</td><td>0.98834</td></tr><tr><td>train_accuracy</td><td>0.15751</td></tr><tr><td>train_loss</td><td>1.07965</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48393</td></tr><tr><td>val_loss</td><td>1.0151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-38</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/d1hnh3rv' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/d1hnh3rv</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_055247-d1hnh3rv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pwucn554 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.1854672011103218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.600023002964349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.131415758468847\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_060125-pwucn554</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/pwucn554' target=\"_blank\">crisp-sweep-39</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/pwucn554' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/pwucn554</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=n554, val_accuracy=0.495, train_accuracy=0.337]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=n554, val_accuracy=0.495, train_accuracy=0.337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.550000011920929\n",
      "        test_loss           0.9588981866836548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▇▅▇█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▆▅▅▅█▄▄▄▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▅▁▅██</td></tr><tr><td>val_loss</td><td>█▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55</td></tr><tr><td>test_loss</td><td>0.9589</td></tr><tr><td>train_accuracy</td><td>0.3372</td></tr><tr><td>train_loss</td><td>1.08127</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.49464</td></tr><tr><td>val_loss</td><td>0.99628</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-sweep-39</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/pwucn554' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/pwucn554</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_060125-pwucn554/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t4mosveu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7391810458490444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6828940832717458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.8031236325303246\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_061008-t4mosveu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/t4mosveu' target=\"_blank\">peachy-sweep-40</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/t4mosveu' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/t4mosveu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=sveu, val_accuracy=0.486, train_accuracy=0.00134] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=sveu, val_accuracy=0.486, train_accuracy=0.00134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5089285969734192\n",
      "        test_loss           1.0185985565185547\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▂</td></tr><tr><td>train_loss</td><td>▁█▅▆▆▆▅▇█▅▄▅▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50893</td></tr><tr><td>test_loss</td><td>1.0186</td></tr><tr><td>train_accuracy</td><td>0.00134</td></tr><tr><td>train_loss</td><td>1.12115</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48571</td></tr><tr><td>val_loss</td><td>1.0402</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-sweep-40</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/t4mosveu' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/t4mosveu</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_061008-t4mosveu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 134h12y7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6213507767580038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6063042015220115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5675955597301576\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_061846-134h12y7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/134h12y7' target=\"_blank\">elated-sweep-41</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/134h12y7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/134h12y7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=12y7, val_accuracy=0.500, train_accuracy=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=12y7, val_accuracy=0.500, train_accuracy=0.113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.512499988079071\n",
      "        test_loss           0.9850040078163147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▃▁▃▃</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▄▄▄█</td></tr><tr><td>val_loss</td><td>█▄▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5125</td></tr><tr><td>test_loss</td><td>0.985</td></tr><tr><td>train_accuracy</td><td>0.11332</td></tr><tr><td>train_loss</td><td>1.07051</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.5</td></tr><tr><td>val_loss</td><td>1.01229</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-41</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/134h12y7' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/134h12y7</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_061846-134h12y7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: thr4cjfg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.914916099261104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5591468582681046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.9921363441378348\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_062724-thr4cjfg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/thr4cjfg' target=\"_blank\">super-sweep-42</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/thr4cjfg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/thr4cjfg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=cjfg, val_accuracy=0.480, train_accuracy=0.00216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=cjfg, val_accuracy=0.480, train_accuracy=0.00216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5375000238418579\n",
      "        test_loss           1.0231300592422485\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▃▂</td></tr><tr><td>train_loss</td><td>▁▇▅▅▆▅▆▆█▄▃▄▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▆██</td></tr><tr><td>val_loss</td><td>█▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.5375</td></tr><tr><td>test_loss</td><td>1.02313</td></tr><tr><td>train_accuracy</td><td>0.00216</td></tr><tr><td>train_loss</td><td>1.09828</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48036</td></tr><tr><td>val_loss</td><td>1.03809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-42</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/thr4cjfg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/thr4cjfg</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_062724-thr4cjfg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m6eypz3n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.711958825828651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.45604626179795865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.6866968511280703\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_063601-m6eypz3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m6eypz3n' target=\"_blank\">pleasant-sweep-43</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m6eypz3n' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m6eypz3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=pz3n, val_accuracy=0.450, train_accuracy=0.000149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=pz3n, val_accuracy=0.450, train_accuracy=0.000149]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.94it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4642857015132904\n",
      "        test_loss            1.066817283630371\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▅▇▅▅▅▅▇▄▁▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅█▇</td></tr><tr><td>val_loss</td><td>█▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.46429</td></tr><tr><td>test_loss</td><td>1.06682</td></tr><tr><td>train_accuracy</td><td>0.00015</td></tr><tr><td>train_loss</td><td>1.08149</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.45</td></tr><tr><td>val_loss</td><td>1.07684</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-43</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m6eypz3n' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m6eypz3n</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_063601-m6eypz3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hbq1mn00 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.3055871147630445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5378261228872275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.0197282412778446\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_064449-hbq1mn00</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hbq1mn00' target=\"_blank\">expert-sweep-44</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hbq1mn00' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hbq1mn00</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=mn00, val_accuracy=0.502, train_accuracy=0.139]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=mn00, val_accuracy=0.502, train_accuracy=0.139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.97it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5589285492897034\n",
      "        test_loss           0.9785515069961548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▅▁▃▆█</td></tr><tr><td>train_loss</td><td>▁▅▄▃▆▅▅▅█▄▄▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55893</td></tr><tr><td>test_loss</td><td>0.97855</td></tr><tr><td>train_accuracy</td><td>0.13921</td></tr><tr><td>train_loss</td><td>1.1021</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50179</td></tr><tr><td>val_loss</td><td>1.00485</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-44</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hbq1mn00' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hbq1mn00</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_064449-hbq1mn00/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vflysvne with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6381496985347082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6548830154089142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.43496666141985774\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_065333-vflysvne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vflysvne' target=\"_blank\">peachy-sweep-45</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vflysvne' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/vflysvne</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=svne, val_accuracy=0.486, train_accuracy=0.00112] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=svne, val_accuracy=0.486, train_accuracy=0.00112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5053571462631226\n",
      "        test_loss           1.1317518949508667\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▄▁▁▂</td></tr><tr><td>train_loss</td><td>▁█▅▇▅▆▃▇▅▇▃▆▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▂▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50536</td></tr><tr><td>test_loss</td><td>1.13175</td></tr><tr><td>train_accuracy</td><td>0.00112</td></tr><tr><td>train_loss</td><td>1.0758</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.48571</td></tr><tr><td>val_loss</td><td>1.14459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-sweep-45</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/vflysvne' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/vflysvne</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_065333-vflysvne/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bymwwe70 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.19070340331838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6683332489272846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2838483214224414\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_070221-bymwwe70</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bymwwe70' target=\"_blank\">proud-sweep-46</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bymwwe70' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bymwwe70</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=we70, val_accuracy=0.520, train_accuracy=0.342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=we70, val_accuracy=0.520, train_accuracy=0.342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5642856955528259\n",
      "        test_loss           0.9513819217681885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▃▆█</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▅▅▅█▄▄▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▅▁▃▆█</td></tr><tr><td>val_loss</td><td>█▅▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.56429</td></tr><tr><td>test_loss</td><td>0.95138</td></tr><tr><td>train_accuracy</td><td>0.34189</td></tr><tr><td>train_loss</td><td>1.07857</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.51964</td></tr><tr><td>val_loss</td><td>0.98627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-46</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bymwwe70' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bymwwe70</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_070221-bymwwe70/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ajxj9kij with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.9061868665449244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6883497531945565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.7437735608863157\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_071100-ajxj9kij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ajxj9kij' target=\"_blank\">likely-sweep-47</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ajxj9kij' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/ajxj9kij</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=9kij, val_accuracy=0.488, train_accuracy=7.44e-5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=9kij, val_accuracy=0.488, train_accuracy=7.44e-5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5053571462631226\n",
      "        test_loss            1.04067063331604\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁█▆▇▆▆▅▇█▆▃▅▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50536</td></tr><tr><td>test_loss</td><td>1.04067</td></tr><tr><td>train_accuracy</td><td>7e-05</td></tr><tr><td>train_loss</td><td>1.11092</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.05559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-47</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/ajxj9kij' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/ajxj9kij</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_071100-ajxj9kij/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bbsh6yjg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.0886445886011442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5810187421902185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.4811676565981257\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_071937-bbsh6yjg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bbsh6yjg' target=\"_blank\">lemon-sweep-48</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bbsh6yjg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bbsh6yjg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=6yjg, val_accuracy=0.488, train_accuracy=0.0117] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=6yjg, val_accuracy=0.488, train_accuracy=0.0117]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5089285969734192\n",
      "        test_loss            1.029874563217163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▅█▂▁▃</td></tr><tr><td>train_loss</td><td>▁█▅▆▆▇▄█▇▇▅▇▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▇▇▇█</td></tr><tr><td>val_loss</td><td>█▂▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.50893</td></tr><tr><td>test_loss</td><td>1.02987</td></tr><tr><td>train_accuracy</td><td>0.01168</td></tr><tr><td>train_loss</td><td>1.10451</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.05769</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-48</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/bbsh6yjg' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/bbsh6yjg</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_071937-bbsh6yjg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: errw5uo6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.0541186517463252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5087737727006699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5238449617348744\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_072814-errw5uo6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/errw5uo6' target=\"_blank\">light-sweep-49</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/errw5uo6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/errw5uo6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=5uo6, val_accuracy=0.448, train_accuracy=0.340]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=5uo6, val_accuracy=0.448, train_accuracy=0.340]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4821428656578064\n",
      "        test_loss           0.9739566445350647\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▆▅█</td></tr><tr><td>train_loss</td><td>▁▃▃▃▅▄▄▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▂▂▂█</td></tr><tr><td>val_loss</td><td>▇█▆▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.48214</td></tr><tr><td>test_loss</td><td>0.97396</td></tr><tr><td>train_accuracy</td><td>0.33973</td></tr><tr><td>train_loss</td><td>1.02896</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.44821</td></tr><tr><td>val_loss</td><td>1.01187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-sweep-49</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/errw5uo6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/errw5uo6</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_072814-errw5uo6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f3clhkmm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.788747588504152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.649456670158536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.088826637044069\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_073652-f3clhkmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/f3clhkmm' target=\"_blank\">earthy-sweep-50</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/f3clhkmm' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/f3clhkmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=hkmm, val_accuracy=0.509, train_accuracy=0.0244] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=hkmm, val_accuracy=0.509, train_accuracy=0.0244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.550000011920929\n",
      "        test_loss           0.9999789595603943\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▃▅▆</td></tr><tr><td>train_loss</td><td>▁▆▄▄▆▅▅▆█▅▃▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▇▇██</td></tr><tr><td>val_loss</td><td>█▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55</td></tr><tr><td>test_loss</td><td>0.99998</td></tr><tr><td>train_accuracy</td><td>0.0244</td></tr><tr><td>train_loss</td><td>1.10413</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50893</td></tr><tr><td>val_loss</td><td>1.02244</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-50</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/f3clhkmm' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/f3clhkmm</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_073652-f3clhkmm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zjajdewh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.328225182742322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6643372328211729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2234242641488229\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_074531-zjajdewh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zjajdewh' target=\"_blank\">fallen-sweep-51</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zjajdewh' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/zjajdewh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.46it/s, v_num=dewh, val_accuracy=0.504, train_accuracy=0.285]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=dewh, val_accuracy=0.504, train_accuracy=0.285]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5571428537368774\n",
      "        test_loss           0.9608461856842041\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▅▃▅█</td></tr><tr><td>train_loss</td><td>▁▄▄▃▅▅▄▅█▄▄▄▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▄▁▃██</td></tr><tr><td>val_loss</td><td>█▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55714</td></tr><tr><td>test_loss</td><td>0.96085</td></tr><tr><td>train_accuracy</td><td>0.28527</td></tr><tr><td>train_loss</td><td>1.08792</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50357</td></tr><tr><td>val_loss</td><td>0.99457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-51</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/zjajdewh' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/zjajdewh</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_074531-zjajdewh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5agjqi0o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.4776810071420774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6885174387130452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.1225037973418177\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_075409-5agjqi0o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/5agjqi0o' target=\"_blank\">rich-sweep-52</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/5agjqi0o' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/5agjqi0o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=qi0o, val_accuracy=0.502, train_accuracy=0.158] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:36<00:00,  1.45it/s, v_num=qi0o, val_accuracy=0.502, train_accuracy=0.158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy          0.550000011920929\n",
      "        test_loss           0.9682884216308594\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▅█</td></tr><tr><td>train_loss</td><td>▁▅▄▃▅▅▅▅█▄▄▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▆▇██</td></tr><tr><td>val_loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55</td></tr><tr><td>test_loss</td><td>0.96829</td></tr><tr><td>train_accuracy</td><td>0.15774</td></tr><tr><td>train_loss</td><td>1.10798</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50179</td></tr><tr><td>val_loss</td><td>1.00058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-52</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/5agjqi0o' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/5agjqi0o</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_075409-5agjqi0o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mmsxy87i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.8161421323347704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.601561014106364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.4061572962361598\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_080252-mmsxy87i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mmsxy87i' target=\"_blank\">stellar-sweep-53</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mmsxy87i' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/mmsxy87i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=y87i, val_accuracy=0.475, train_accuracy=7.44e-5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.46it/s, v_num=y87i, val_accuracy=0.475, train_accuracy=7.44e-5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.49642857909202576\n",
      "        test_loss           1.1410186290740967\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁</td></tr><tr><td>train_loss</td><td>▄█▆▇▄▅▃▅▄▆▁▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▄▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.49643</td></tr><tr><td>test_loss</td><td>1.14102</td></tr><tr><td>train_accuracy</td><td>7e-05</td></tr><tr><td>train_loss</td><td>1.06755</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.475</td></tr><tr><td>val_loss</td><td>1.15063</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-53</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mmsxy87i' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/mmsxy87i</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_080252-mmsxy87i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hy75496w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.3017225037132878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5539940983005633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.7554705431721769\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_081127-hy75496w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hy75496w' target=\"_blank\">true-sweep-54</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hy75496w' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hy75496w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=496w, val_accuracy=0.427, train_accuracy=0.356]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=496w, val_accuracy=0.427, train_accuracy=0.356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4571428596973419\n",
      "        test_loss           0.9920885562896729\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▅█</td></tr><tr><td>train_loss</td><td>▁▃▃▃▅▄▅▄█▃▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▂▂▂█</td></tr><tr><td>val_loss</td><td>██▆▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.45714</td></tr><tr><td>test_loss</td><td>0.99209</td></tr><tr><td>train_accuracy</td><td>0.35618</td></tr><tr><td>train_loss</td><td>1.02346</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.42679</td></tr><tr><td>val_loss</td><td>1.02482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-54</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/hy75496w' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/hy75496w</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_081127-hy75496w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mflxu71t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.236229484547141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6054070555556839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.1886342874783449\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_082000-mflxu71t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mflxu71t' target=\"_blank\">fallen-sweep-55</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mflxu71t' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/mflxu71t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 626])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 882 K \n",
      "-------------------------------\n",
      "882 K     Trainable params\n",
      "0         Non-trainable params\n",
      "882 K     Total params\n",
      "3.528     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=u71t, val_accuracy=0.386, train_accuracy=0.279]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=u71t, val_accuracy=0.386, train_accuracy=0.279]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.39821428060531616\n",
      "        test_loss           1.0222467184066772\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁█▆█▅</td></tr><tr><td>train_loss</td><td>▄▅▃▁▁█▇▃▄▃▄▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▂▁█▇▂</td></tr><tr><td>val_loss</td><td>▃▆▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.39821</td></tr><tr><td>test_loss</td><td>1.02225</td></tr><tr><td>train_accuracy</td><td>0.27902</td></tr><tr><td>train_loss</td><td>0.96382</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.38571</td></tr><tr><td>val_loss</td><td>1.06331</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-55</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/mflxu71t' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/mflxu71t</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_082000-mflxu71t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m75nedqn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6174173988220115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5805115212327063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.5469982630612509\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_082837-m75nedqn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m75nedqn' target=\"_blank\">lyric-sweep-56</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m75nedqn' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m75nedqn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:34<00:00,  1.48it/s, v_num=edqn, val_accuracy=0.475, train_accuracy=0.172]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:34<00:00,  1.48it/s, v_num=edqn, val_accuracy=0.475, train_accuracy=0.172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.47678571939468384\n",
      "        test_loss           0.9912393689155579\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▅▂▃▁</td></tr><tr><td>train_loss</td><td>▁▄▃▃▅▄▅▄█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅█</td></tr><tr><td>val_loss</td><td>█▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.47679</td></tr><tr><td>test_loss</td><td>0.99124</td></tr><tr><td>train_accuracy</td><td>0.17232</td></tr><tr><td>train_loss</td><td>1.07785</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.475</td></tr><tr><td>val_loss</td><td>1.01669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-56</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/m75nedqn' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/m75nedqn</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_082837-m75nedqn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2g1gzpqf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7842522958152314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6655077856281502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 0.8755885945328293\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_083715-2g1gzpqf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2g1gzpqf' target=\"_blank\">breezy-sweep-57</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2g1gzpqf' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2g1gzpqf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=zpqf, val_accuracy=0.488, train_accuracy=0.0035] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=zpqf, val_accuracy=0.488, train_accuracy=0.0035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5107142925262451\n",
      "        test_loss            1.013785481452942\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>█▁▂▃▃</td></tr><tr><td>train_loss</td><td>▁█▅▆▆▆▅▆█▅▄▅▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁████</td></tr><tr><td>val_loss</td><td>█▃▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.51071</td></tr><tr><td>test_loss</td><td>1.01379</td></tr><tr><td>train_accuracy</td><td>0.0035</td></tr><tr><td>train_loss</td><td>1.13141</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.4875</td></tr><tr><td>val_loss</td><td>1.03478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-57</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/2g1gzpqf' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/2g1gzpqf</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_083715-2g1gzpqf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: woh2the6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.7548078306831876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5992864921550629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.3119111448270309\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_084559-woh2the6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/woh2the6' target=\"_blank\">grateful-sweep-58</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/woh2the6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/woh2the6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=the6, val_accuracy=0.502, train_accuracy=0.0955]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:35<00:00,  1.47it/s, v_num=the6, val_accuracy=0.502, train_accuracy=0.0955]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5410714149475098\n",
      "        test_loss           0.9972160458564758\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▇▁▂█▇</td></tr><tr><td>train_loss</td><td>▁▄▄▃▆▅▅▅█▄▄▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.54107</td></tr><tr><td>test_loss</td><td>0.99722</td></tr><tr><td>train_accuracy</td><td>0.09554</td></tr><tr><td>train_loss</td><td>1.07939</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50179</td></tr><tr><td>val_loss</td><td>1.01737</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-58</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/woh2the6' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/woh2the6</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_084559-woh2the6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v87juvjb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6469855144561347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.6876097286584276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.2959985898689177\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_085438-v87juvjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v87juvjb' target=\"_blank\">silver-sweep-59</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v87juvjb' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/v87juvjb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=uvjb, val_accuracy=0.509, train_accuracy=0.135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:37<00:00,  1.44it/s, v_num=uvjb, val_accuracy=0.509, train_accuracy=0.135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.92it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.5589285492897034\n",
      "        test_loss            0.971709132194519\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▄▁▂▅█</td></tr><tr><td>train_loss</td><td>▁▅▄▃▆▅▅▅█▄▄▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇█</td></tr><tr><td>val_loss</td><td>█▃▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>0.55893</td></tr><tr><td>test_loss</td><td>0.97171</td></tr><tr><td>train_accuracy</td><td>0.1346</td></tr><tr><td>train_loss</td><td>1.09606</td></tr><tr><td>trainer/global_step</td><td>700</td></tr><tr><td>val_accuracy</td><td>0.50893</td></tr><tr><td>val_loss</td><td>1.00201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-59</strong> at: <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/v87juvjb' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/v87juvjb</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_085438-v87juvjb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h0gtbtk1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \theads: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fft: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_mels: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw1: 1.6460423254312508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw2: 0.5211632951261211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tw3: 1.334032693006257\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/git_repos/Deep-Learning-Mini-Project/wandb/run-20230331_090321-h0gtbtk1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/h0gtbtk1' target=\"_blank\">rare-sweep-60</a></strong> to <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-miniproject/cough-classifier' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/sweeps/2d63ds5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-miniproject/cough-classifier/runs/h0gtbtk1' target=\"_blank\">https://wandb.ai/dl-miniproject/cough-classifier/runs/h0gtbtk1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/deep_learning/lib/python3.9/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Size of random sample of data: torch.Size([1, 64, 313])\n",
      "['COVID-19' 'healthy' 'symptomatic']\n",
      "{'healthy': 2830, 'symptomatic': 2014, 'COVID-19': 756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | KWT  | 841 K \n",
      "-------------------------------\n",
      "841 K     Trainable params\n",
      "0         Non-trainable params\n",
      "841 K     Total params\n",
      "3.368     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:41<00:00,  1.38it/s, v_num=btk1, val_accuracy=0.495, train_accuracy=0.0871]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 140/140 [01:41<00:00,  1.38it/s, v_num=btk1, val_accuracy=0.495, train_accuracy=0.0871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4928571283817291\n",
      "        test_loss           1.0034592151641846\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"sweep_config = {\n",
    "  \"method\": \"bayes\",\n",
    "  \"metric\": {\n",
    "        \"name\": \"val_accuracy\",\n",
    "        \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"parameters\": {\n",
    "    \"batch_size\": {\n",
    "        \"values\": [16, 32, 64]\n",
    "    },\n",
    "    \"max_epochs\": {\n",
    "        \"values\": [5, 10, 20, 30]\n",
    "    },\n",
    "    \"sample_rate\": {\n",
    "      \"values\": [16000] # Increasing this value will have a significant impact how much data you can fit into memory 48000 aprox double the size of 22050\n",
    "    },\n",
    "    \"n_fft\": {\n",
    "      \"values\": [512, 1024]\n",
    "    },\n",
    "    \"n_mels\": {\n",
    "      \"values\": [32, 64]\n",
    "    },\n",
    "    \"w1\": {\n",
    "        \"min\": 1.0,\n",
    "        \"max\": 2.0\n",
    "    },\n",
    "    \"w2\": {\n",
    "        \"min\": 0.01,\n",
    "        \"max\": 0.7\n",
    "    },\n",
    "    \"w3\": {\n",
    "        \"min\": 0.4,\n",
    "        \"max\": 2.0\n",
    "    },\n",
    "    \"dim\": {\n",
    "      \"values\": [128, 256, 512]\n",
    "    },\n",
    "    \"heads\": {\n",
    "      \"values\": [4, 8, 16, 32]\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='cough-classifier', entity='dl-miniproject')\n",
    "\n",
    "wandb.agent(sweep_id, function=train_new, count=100)\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0b69965270e405d09dae21e4ae2ea2cc233b709569664f2de57e4e4d7e55573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
